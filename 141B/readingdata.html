<!DOCTYPE html>
<!-- This page was generated by GitHub Pages using the Cayman theme by Jason Long -->
<html lang="en-us">
  <head>
    <meta charset="UTF-8">
    <title>141B: Reading Data</title>
    <meta name="viewport" content="width=device-width, initial-scale=1">
    <link rel="stylesheet" type="text/css" href="stylesheets/normalize.css" media="screen">
    <link href='https://fonts.googleapis.com/css?family=Open+Sans:400,700' rel='stylesheet' type='text/css'>
    <link rel="stylesheet" type="text/css" href="../stylesheets/stylesheet.css" media="screen">
    <link rel="stylesheet" type="text/css" href="../stylesheets/github-light.css" media="screen">
  </head>
  <body>
    <section class="page-header">
      <h1 class="project-name">141B: Lesson 6</h1>
      <h2 class="project-tagline">Reading Data</h2>
    </section>

    <section class="main-content">
<h2>Python Input</h2>

<h3>Follow along with the <a href="code/reading_data.ipynb">python notebook</a>.</h3>

Python has built in input/output functionality, and it is important to understand it.
There are faster ways to load well formatted files, like CSVs, excel files, etc, but you may need to fall back on this basic functionality.
The <code>open</code> command creates a file object, which is an iterator, and has methods <code>read, readline, write, seek</code> which allow you to move and read within the file.  The open command takes the filename (and path), and mode (read, write, both).
The file object is also an iterator, and the <code>next</code> method returns each line in succession.

<h3>Checkpoint: Read over section 7.2 in <a href="https://docs.python.org/2/tutorial/inputoutput.html">python docs</a>.</h3>

      <div class="youtube">
	<iframe width="560" height="315" src="https://www.youtube.com/embed/dyCLgKATYc8" frameborder="0" allowfullscreen></iframe>
	<b>Reading files with python</b>
      </div>

<h2>CSV package</h2>
The CSV package is specifically designed for reading delimited files.  It gives us back an iterator that works much like the file object, except that you can specify what is the delimiter (tab, space, comma, etc.), and what is the quote character (typically "").
This way the commas that are in quoted regions will not be interpretted as delimiters.

<h3>Checkpoint: Read over <a href="https://docs.python.org/2/library/csv.html">the CSV documentation</a>, paying attention to the reader and writer objects.</h3>

      <div class="youtube">
	<iframe width="560" height="315" src="https://www.youtube.com/embed/UR4GbRaPxa8" frameborder="0" allowfullscreen></iframe>
	<b>CSV reader</b>
      </div>

<h2>Pandas read_*</h2>
We have not gone over the Pandas dataframe yet (it is a data table, like what is in R), but we can see how advanced the package is just in its I/O.
The <code>read_csv</code> command has a few different ways of working.  If you specify that you want an iterator, with the iterator argument, then you can get something that works like the CSV reader object.
You can also specify a chunksize, and then it returns an iterator that will read the file in chunks (the first k likes, then the next k, etc.), which is great for files that you cannot store in memory. 
By default <code>read_csv</code> loads the file all at once.    

<h3>Checkpoint: Read through the <a href="http://pandas.pydata.org/pandas-docs/stable/io.html">Pandas I/O documentation</a> for <code>read_csv, read_excel, read_hdf</code> and pay attention to the arguments.</h3>

      <div class="youtube">
	<iframe width="560" height="315" src="https://www.youtube.com/embed/aeHEVVtRii4" frameborder="0" allowfullscreen></iframe>
	<b>Pandas read_csv</b>
      </div>
      
<h2>Data latency and reading in chunks</h2>
We have talked about how the computer architecture determines the speed at which you can access different bits of memory.
For example, to read 1MB from the main memory, which is where your variables are stored, takes roughly 0.25 milliseconds.
To read 1MB from a solid state drive takes 1 millisecond, and to read 1MB from a hard disk takes 20 milliseconds.
Reading data over a network depends on the speed of routing packets across that network, but it typically is greater than 10 times as slow as reading from disk.
When working with big data, it is very common to have many GB of data in multiple drives over a network.
The standard way to deal with this is to read the data from drive sequentially, and only store what is needed in memory.
You can find a more complete list of latency numbers <a href="https://gist.github.com/jboner/2841832">in this Github page, adapted from a talk by Jeff Dean</a>.

Pandas is great for this, because the <code>read_*</code> commands can return an iterator by using the <code>iterator, chunksize</code> as we have already meantioned.
If you specify these arguments then instead of returning a Dataframe, it returns a TextFileReader object.
This TextFileReader is iterable and 

<h3>Checkpoint: read <a href="http://pandas.pydata.org/pandas-docs/stable/io.html#io-chunking">this brief section</a> on chunking in the docs page</h3>

This next video is based on <a href="code/reading_chunks.ipynb">this python notebook</a> and is an introduction to how you can use chunking to calculate statistics without reading all of the data at once.

<div class="youtube">
  <iframe width="560" height="315" src="https://www.youtube.com/embed/AVe4pY0XWU4" frameborder="0" allowfullscreen></iframe>
  <b>Pandas chunksize</b>
</div>

<h3>Checkpoint: Figure out what is going on in each cell in the reading_chunks notebook.</h3>

     <footer class="site-footer">
	Copyright James Sharpnack &copy; 2016
     </footer>
     
    </section>

  
  </body>
</html>
